{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c4970c",
   "metadata": {},
   "source": [
    "<img src=\"https://devra.ai/analyst/notebook/3448/image.jpg\" style=\"width: 100%; height: auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6caafa7",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; border-radius:15px; padding:15px; color:white; margin:0; font-family: 'Orbitron', sans-serif; background: #2E0249; background: #11001C; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.3); overflow:hidden; margin-bottom: 1em;\">\n",
    "  <div style=\"font-size:150%; color:#FEE100\"><b>Tip Prediction and Exploratory Analysis Notebook</b></div>\n",
    "  <div>This notebook was created with the help of <a href=\"https://devra.ai/ref/kaggle\" style=\"color:#6666FF\">Devra AI</a></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb340d7",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Data Loading](#Data-Loading)\n",
    "- [Data Cleaning and Preprocessing](#Data-Cleaning-and-Preprocessing)\n",
    "- [Exploratory Data Analysis (EDA)](#Exploratory-Data-Analysis)\n",
    "- [Correlation Analysis](#Correlation-Analysis)\n",
    "- [Predictive Modeling](#Predictive-Modeling)\n",
    "- [Conclusion](#Conclusion)\n",
    "\n",
    "If you find this notebook useful, please consider upvoting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning libraries for predictive modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Configure matplotlib for inline plotting if only plt is imported\n",
    "plt.switch_backend('Agg')\n",
    "\n",
    "# Set aesthetic parameters for seaborn\n",
    "sns.set(style='whitegrid', palette='muted', color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0dfe81",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We load the tip dataset from the CSV file. The dataset includes total bill amounts, tip amounts, and several categorical variables that provide contextual information for each record. Note that since there are no explicit date columns in this dataset, we do not perform any date parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8192ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tip dataset\n",
    "data_path = 'customertipping\\dataset\\tip.csv'\n",
    "df = pd.read_csv(data_path, delimiter=',')\n",
    "\n",
    "# Display the first few rows of the dataset (this output will be generated upon execution)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a91414",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "In this section we check for missing values, data consistency, and convert categorical variables appropriately if needed. Although our dataset appears clean, it is important to show these standard procedures. For example, if other users encounter missing data, the methods used here could help address them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264baea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and data types\n",
    "print('Missing values in each column:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Review data types\n",
    "print('\\nData types:')\n",
    "print(df.dtypes)\n",
    "\n",
    "# Ensure categorical variables are of type 'category'\n",
    "categorical_cols = ['sex', 'smoker', 'day', 'time']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# Check summary of the dataset\n",
    "print('\\nDataset summary:')\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefccd31",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "We now dive into various visualizations to gain insights from the dataset. The following plots will help us see distributions of numerical variables, counts for categorical variables, and pairwise relationships among the numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd87c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for numerical variables\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, col in enumerate(['total_bill', 'tip', 'size'], 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.histplot(df[col], kde=True, color='teal')\n",
    "    plt.title(f'Histogram of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Count plots for categorical features\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.countplot(x='sex', data=df, palette='pastel')\n",
    "plt.title('Count of Sex')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.countplot(x='smoker', data=df, palette='pastel')\n",
    "plt.title('Count of Smoker')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.countplot(x='day', data=df, palette='pastel')\n",
    "plt.title('Count of Day')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.countplot(x='time', data=df, palette='pastel')\n",
    "plt.title('Count of Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pair plot for numerical variables\n",
    "sns.pairplot(df[['total_bill', 'tip', 'size']])\n",
    "plt.show()\n",
    "\n",
    "# Box plot to visualize distribution of tip by day\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='day', y='tip', data=df, palette='Set2')\n",
    "plt.title('Tip Distribution by Day')\n",
    "plt.show()\n",
    "\n",
    "# Violin plot for tip distribution by time\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(x='time', y='tip', data=df, palette='Set3')\n",
    "plt.title('Tip Distribution by Time')\n",
    "plt.show()\n",
    "\n",
    "# Strip plot for a detailed view of tip by size\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.stripplot(x='size', y='tip', data=df, jitter=True, palette='coolwarm')\n",
    "plt.title('Tip vs Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a84601",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "\n",
    "We now compute a correlation matrix for the numeric variables. A correlation heatmap will only be generated if there are at least four numeric columns. In our case, there are three numeric fields (total_bill, tip, and size); hence we will simply display the correlation matrix.\n",
    "\n",
    "In scenarios with more numeric features, a heatmap can highlight multicollinearity concerns or reveal interesting patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5998098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns for correlation analysis\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "print('Correlation Matrix:')\n",
    "corr_matrix = numeric_df.corr()\n",
    "print(corr_matrix)\n",
    "\n",
    "if len(numeric_df.columns) >= 4:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Correlation Heatmap of Numeric Features')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('\\nNot enough numeric columns for a heatmap. Displaying correlation matrix is sufficient.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85076a1",
   "metadata": {},
   "source": [
    "## Predictive Modeling\n",
    "\n",
    "Our objective is to predict the tip amount based on features such as total_bill, sex, smoker, day, time, and size. Since tip prediction is a continuous variable, regression is suitable. We perform the following steps:\n",
    "\n",
    "1. Convert categorical variables into dummy/indicator variables.\n",
    "2. Split the dataset into training and testing subsets.\n",
    "3. Build a linear regression model and measure its performance using the R-squared score.\n",
    "4. Compute permutation importance to gauge feature relevance.\n",
    "\n",
    "Enjoy the journey into predictive insights with a hint of dry humor in the code comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for predictive modeling\n",
    "# Using pd.get_dummies for one-hot encoding the categorical variables\n",
    "df_model = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_model.drop('tip', axis=1)\n",
    "y = df_model['tip']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the R-squared score to evaluate predictive performance\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R-squared Score: {r2:.3f}')\n",
    "\n",
    "# Compute permutation importance\n",
    "result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42, scoring='r2')\n",
    "perm_importances = pd.Series(result.importances_mean, index=X.columns)\n",
    "\n",
    "# Plotting permutation importances using a horizontal bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "perm_importances.sort_values().plot.barh()\n",
    "plt.xlabel('Mean Importance')\n",
    "plt.title('Permutation Importance of Features')\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted tip values to visually assess the model performance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, color='navy')\n",
    "plt.xlabel('Actual Tip')\n",
    "plt.ylabel('Predicted Tip')\n",
    "plt.title('Actual vs Predicted Tip')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', lw=2)  # Diagonal line for perfect prediction\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb26ec3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook walked through the entire analytical process starting from data loading and cleaning to exploratory data analysis and predictive modeling for the tip dataset. The visualization techniques provided various insights into the underlying distributions and relationships in the data, while the regression model delivered a quantifiable performance metric. Future work may include more sophisticated models, feature engineering, or additional cross-validation to further enhance prediction accuracy.\n",
    "\n",
    "Thank you for reading. If you found the notebook useful, please upvote it."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8576977,
     "sourceId": 13508786,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "amlprojectvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
